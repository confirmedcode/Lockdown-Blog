---
title: Can You Trust the Apps and Sites You Use?
layout: post
date: '2020-12-02 00:00:00 -0800'
author: Lockdown Privacy
---

#### Let's hope every tech company steals this idea.
<!--more-->

When you send a photo to someone, your messaging app actually first sends the photo to an app‚Äôs server, which then sends the photo to them:

![](/assets/images/1*KKVbLVyMWiypj0Qaopg27A.png)

And sure, in the 90‚Äôs, this might have been what happened. But somewhere along the line, someone figured out how to profit from user data, and so now here‚Äôs what *actually* happens:

![](/assets/images/1*vHOaHP4CGZdluwt7m3xoOw.png)

And that‚Äôs just sending photos. Today, you give apps access to your camera, location, microphone, contacts, browsing habits, even your medical records. After you tap ‚ÄúAllow‚Äù once, an app can even upload your entire photo and video library to their servers in the background while you‚Äôre sleeping.

The Internet is facilitating an [insane](https://theintercept.com/2017/04/24/stop-using-unroll-me-right-now-it-sold-your-data-to-uber/) [free-for-all](https://www.theverge.com/2018/4/24/17275994/yahoo-sec-fine-2014-data-breach-35-million) [for](https://www.forbes.com/sites/kashmirhill/2014/10/03/god-view-uber-allegedly-stalked-users-for-party-goers-viewing-pleasure/#75ddf2383141) [our](https://www.npr.org/sections/thetwo-way/2017/03/14/520123490/vibrator-maker-to-pay-millions-over-claims-it-secretly-tracked-use) [personal](https://www.reuters.com/article/us-facebook-privacy-firing/facebook-employee-fired-over-bragging-about-access-to-user-information-idUSKBN1I334E) [data](https://www.clickondetroit.com/news/concerns-over-misuse-of-childrens-online-data-grow-as-apps-illegally-collect-sell-information), with potential consequences getting [worse](https://www.nytimes.com/2018/03/04/technology/fake-videos-deepfakes.html). Apps even exploit this data with [behavioral science](https://www.ibtimes.com/how-uber-other-digital-platforms-could-trick-us-using-behavioral-science-unless-we-2791467) to squeeze every [dollar](https://clark.com/shopping-retail/mac-users-being-fed-pricier-hotel-searches/) or [minute](https://www.businessinsider.com/how-app-developers-keep-us-addicted-to-our-smartphones-2018-1) out of their users, when it‚Äôs [clearly](https://www.washingtonpost.com/news/monkey-cage/wp/2018/08/06/its-no-accident-that-facebook-is-so-addictive/?utm_term=.1058706f817b) against the [users‚Äô best interests](https://www.vox.com/the-goods/2018/10/30/18044678/kids-apps-gaming-manipulative-ads-ftc). Today, companies have every incentive to exploit our data for profit, and no incentive to protect our privacy.

Since we‚Äôre only going to rely more on apps over time, the critical question is:

## **How do you know if you can trust an app?**

### Trust Through Privacy Policy?

When you ask a company about protecting your data, they respond by telling you to read their Privacy Policy, which is a document they wrote (or [copy-pasted](https://duckduckgo.com/?q=privacy+policy+generator)) that promises they‚Äôll protect your data.

But wait, isn‚Äôt that circular logic? I should trust that they‚Äôre protecting my data because‚Ä¶ they have a document that says they‚Äôll protect my data? How do I know they‚Äôre doing any of the things they claim in the Privacy Policy?

It turns out it‚Äôs impossible to know if an app company is violating their Privacy Policy (or violating privacy laws), because there‚Äôs literally nothing stopping them: they‚Äôre Privacy *Policies*, not Privacy *Proofs.* Not only that, they‚Äôre actually not [legally binding](https://ir.lawnet.fordham.edu/iplj/vol27/iss1/5/), and in the rare cases when companies actually *do *get caught, [the](https://www.abine.com/blog/2012/facebook-privacy-violated-by-new-ads/) [penalties](https://www.theverge.com/2018/4/24/17275994/yahoo-sec-fine-2014-data-breach-35-million) [are](https://uk.reuters.com/article/us-facebook-france/facebook-fined-150000-euros-by-french-data-watchdog-idUKKCN18C10C) [unbelievably light](http://www.consumerwatchdog.org/blog/google-ruling-shows-need-do-not-track-and-strong-antitrust-action). And as recent government (in)action on [data breaches](https://www.reuters.com/article/us-usa-equifax-cfpb/exclusive-u-s-consumer-protection-official-puts-equifax-probe-on-ice-sources-idUSKBN1FP0IZ), [ISP privacy rules](https://www.npr.org/2017/03/28/521831393/congress-overturns-internet-privacy-regulation), and [net neutrality](https://www.cnet.com/news/net-neutrality-is-now-really-officially-dead-open-internet-congress-now-what/) show, often there are no penalties at all.

Privacy Polices and regulations do not create real trust, and they only serve to provide a false sense of security or privacy.

### Trust Through Pricing?

It‚Äôs a common saying on the internet: ‚ÄúIf the product is free, then you‚Äôre the product.‚Äù And while that‚Äôs sometimes true since revenue must come from somewhere, some people make the [logical fallacy](https://en.wikipedia.org/wiki/Denying_the_antecedent) of thinking the inverse must also be true: ‚ÄúIf the product is not free, then you‚Äôre not the product.‚Äù

Due to this mistake, some people use price as a criterion when choosing apps to use, by looking for apps that aren‚Äôt free and making the false assumption that non-free products will not exploit their data for profit.

Of course, it‚Äôs very possible and just as likely for a company to both charge you for an app while also profiting off of your data or having poor security. Therefore, pricing is a bad criterion for finding an app that you can trust.

### Trust Through Aesthetics/Design?

Woah, those app screenshots look so sleek! And their website is so colorful and tastefully designed, with beautiful animations that you simply can‚Äôt resist. Why would an adorable cartoon bear lie to you? Is that even possible?

Well sadly, yes ‚Äî cartoon characters lie all the time. Since they were created by a human and their dialogue is written by a human, an adorable cartoon bear is not less likely to exploit your personal data for profit. It might look cuter while doing it though.

The aesthetics of a website might tell you that that they spent $20 on a SquareSpace theme (or pirated it), but say nothing about how trustable an app or service is ‚Äî it‚Äòs even possible that the company skimped on data security in order to spend more on their website‚Äôs design and animations.

### Trust Through Popularity?

If all your friends jumped off a digital bridge, would you? At one point, Yahoo had over three billion accounts, and in 2013, they broke the world record üéâfor biggest data breach ever, by a [very long shot](https://www.csoonline.com/article/2130877/the-biggest-data-breaches-of-the-21st-century.html). Since then, there have been many more breaches of tens or hundreds of millions accounts of other companies. And these are only counting disclosed and known breaches ‚Äî nobody knows what the real numbers are.

Popularity isn‚Äôt a reliable proxy of how trustworthy an app is. In fact, there are even scam apps that make it into the [top charts](https://blog.lockdownprivacy.com/2020/11/25/how-to-make-80000.html) of the App Store.

## So what actually creates trust?

Apps should have to *earn the trust of its users*, especially when there are such strong financial incentives for companies to simply lie and abuse user data.

To earn user trust, apps should be fully transparent‚Äî the public should be able to see everything the app and its servers are doing, so that anyone can verify that there‚Äôs no negligent, dishonest, or even malicious activity. In other words: trust through transparency.

### Trust Through Transparency

Full transparency means making the *entire operation* of an app public and verifiable, from the app code on your phone or computer, to the server code and infrastructure on the cloud, to the actions of the company‚Äôs employees, *plus* proof of all of that. It‚Äôs *everything *that touches your data. Everything.

If getting full and verifiable transparency from the apps we use every day seems like a radical idea, it‚Äôs because we‚Äôve been trained for so long to expect so little from companies. We‚Äôve been trained to upload our personal data, cross our fingers, and simply hope for the best. The truth is, if we‚Äôre giving companies our most sensitive personal information, why shouldn‚Äôt we expect them to give us proof of exactly what they‚Äôre doing with it?

### A Standard For Transparency

To be clear, *partial* transparency is insufficient and misleading, because it still allows ‚Äúbad bits‚Äù to be hidden, defeating the purpose of transparency. For example, a company hiding just a small part of their server code is still able to secretly copy all user data to unknown third parties from their servers.

So how do we know if an app is being fully transparent, versus only partially transparent or not transparent at all?

A standard for full transparency doesn‚Äôt exist today, so we‚Äôre creating one and giving it away for free.

This new standard is called **[Openly Operated](https://openlyoperated.org)**, because full transparency requires the entire* operation* of an app to be *open* and verifiable. This includes making public all app source code, server code, infrastructure, and employee actions, as well as providing proof of accuracy and validity. It‚Äôs like giving the public read-only access to the app operator‚Äôs Admin console (example [here](https://openlyoperated.org/report/openlyoperated#read-only-account)).

How this is different from apps today? Here‚Äôs the photo-sending example from the beginning again ‚Äî except this time, the app is Openly Operated:

![](/assets/images/1*rJLMAkXuf-6lTJj6Qj1Oqw.png)

Unlike the earlier examples, the Openly Operated [certification process](https://openlyoperated.org/how-to) forces the app to be fully and verifiably transparent, preventing the app‚Äôs operators from hiding privacy and security issues. This process, at a high level, is:

1. The app fulfills specific **[requirements](https://openlyoperated.org/how-to#fulfill-requirements)** to demonstrate full transparency, and uses direct references to [source code](https://openlyoperated.org/how-to#open-source), [infrastructure](https://openlyoperated.org/how-to#open-infrastructure), and other evidence to [prove the app‚Äôs privacy or security claims](https://openlyoperated.org/how-to#claims-with-proof).

1. Combine these requirements and proof of claims into an Openly Operated **[Audit Kit](https://openlyoperated.org/how-to#assemble-audit-kit)** that anyone can publicly view and verify.

1. Get matched with independent [auditors](https://openlyoperated.org/auditors), who verify the Audit Kit to produce public Openly Operated **[Audit Reports](https://openlyoperated.org/reports)**, detailing their verifications and providing a summary.

This lets everyone participate in ‚Äútrust through transparency‚Äù: users who are more technical can perform verifications themselves by diving into the nitty gritty details in the Audit Kit, while less tech-savvy users can read the independent Audit Reports and summaries. Openly Operated‚Äôs transparency is the opposite of the status quo, where apps simply tell users to read their totally unproven and unverifiable Privacy Policy.

[Openly Operated](https://openlyoperated.org) is a free certification. [Its mission](https://openlyoperated.org/about-us) is for all apps to earn trust through transparency, so all [documentation](https://openlyoperated.org/how-to) is available at no cost, and companies pay nothing to license the certification. We‚Äôve even [built examples](https://openlyoperated.org/reports) to show that Openly Operated apps are possible. These are more than proof-of-concepts ‚Äî they‚Äôre in production, fully functional, and are operating at scale with real users.

## Everything Should Be Openly Operated

Companies have been blatantly dishonest with how they handle and secure user data for too long. Since its creation until now, Facebook has had a privacy setting for user posts labeled ‚ÄúOnly Me‚Äù. To any regular person, ‚ÄúOnly Me‚Äù has a simple meaning: me, and literally nobody else.

But over the last ten years, we‚Äôve learned the hard way that Facebook has a very different definition of ‚ÄúOnly Me‚Äù. To Facebook, ‚ÄúOnly Me‚Äù means ‚ÄúMe and [All Of](https://www.cbsnews.com/news/facebook-your-personal-info-for-sale/) [Facebook‚Äôs](http://content.time.com/time/nation/article/0,8599,1532225,00.html) [Advertisers](http://fortune.com/2017/10/27/facebook-russian-election-ads/) and [Their](https://www.bloomberg.com/news/articles/2018-04-04/facebook-scans-what-you-send-to-other-people-on-messenger-app) [Partners](https://www.axios.com/facebook-whatsapp-targeted-ads-user-privacy-c1e18e9b-ed76-4954-ab74-a64a88647e8c.html) and Some Of [Facebook‚Äôs](http://fortune.com/2018/04/03/facebook-videos-delete-personal-data/) [25,000](https://motherboard.vice.com/en_us/article/bjp9zv/facebook-employees-look-at-user-data) [Employees](https://thehackernews.com/2015/02/facebook-acccount-password.html) and Some [Unknown Number](https://www.theverge.com/2019/5/6/18530887/facebook-instagram-ai-data-labeling-annotation-private-posts-outsourced) [Of Contractors](https://www.reuters.com/article/us-facebook-privacy-firing/facebook-employee-fired-over-bragging-about-access-to-user-information-idUSKBN1I334E) and [Facebook Apps That Friends](https://www.rappler.com/technology/news/200508-cambridge-analytica-other-facebook-quiz-apps-brittany-kaiser) or [I Have Used](https://www.cnbc.com/2018/04/08/cubeyou-cambridge-like-app-collected-data-on-millions-from-facebook.html) and [Those Apps‚Äô](http://www.latimes.com/business/la-fi-facebook-sells-data-to-chinese-20180605-story.html) [Employees](https://www.theguardian.com/news/2018/mar/20/facebook-data-cambridge-analytica-sandy-parakilas) and [Anyone Those Apps](https://www.cnbc.com/2018/04/16/facebook-collects-data-even-when-youre-not-on-facebook.html) [Share Or Sell Data To](https://www.marketwatch.com/story/spooked-by-the-facebook-privacy-violations-this-is-how-much-your-personal-data-is-worth-on-the-dark-web-2018-03-20)‚Ä¶ [Maybe](https://www.ftc.gov/news-events/press-releases/2011/11/facebook-settles-ftc-charges-it-deceived-consumers-failing-keep)‚Äù.

![Probably need a smaller font to fit the truth here.](/assets/images/1*El8rgOdv_tVUSkEwkqenZg.png)*Probably need a smaller font to fit the truth here.*

Privacy and security scandals happen every week not because companies are evil, but because like anything else, companies operate on incentives. In a world where there‚Äôs no way to verify an app‚Äôs security or privacy claims, why should a company be honest and make less money, while their competitors are being dishonest and making more money? Current incentives give dishonest and insecure companies an edge to grow faster, compete more efficiently, spend more on marketing, and capture the most customers.

Openly Operated provides a structured way for companies to *prove* their privacy and security claims. Users have nothing to lose and everything to gain by demanding transparency from the apps they give their personal data to. The question shouldn‚Äôt be ‚ÄúWhy should the apps I use be transparent?‚Äù ‚Äî it should be ‚ÄúWhy *aren‚Äôt* the apps I use transparent? What are they hiding?‚Äù

Learn more at [OpenlyOperated.org](https://openlyoperated.org). Whether you‚Äôre a user curious about the [many benefits](https://openlyoperated.org/user-benefits) of transparency, an engineer [building apps people can trust](https://openlyoperated.org/how-to), or a company that wants to [win customers while increasing security](https://openlyoperated.org/for-companies), Openly Operated has something to offer you.

Wouldn't it be nice if "Only Me" really meant "Only Me"?
